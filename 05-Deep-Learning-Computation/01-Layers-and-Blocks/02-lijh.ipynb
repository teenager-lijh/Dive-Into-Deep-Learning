{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查询张量所在设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x20a58eef2e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count() # 返回 gpu 的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回第 0 号 gpu 设备的抽象表示\n",
    "torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.device('device_name') 只是用来获取设备的抽象表示\n",
    "\n",
    "X_cpu = torch.ones(2, 3, device=torch.device('cpu'))\n",
    "X_gpu = torch.ones(2, 3, device=torch.device('cuda'))\n",
    "X_gpu_0 = torch.ones(2, 3, device=torch.device('cuda:0'))\n",
    "# 如果要执行计算，那么创建的所有参与同一个计算的张量应该在同一个 cpu 或者 gpu 上\n",
    "# 那么运算的结果也会存储在参与运算所在的张量的设备上\n",
    "# 在 gpu 和 cpu 之间移动数据是非常慢的\n",
    "# 所以框架不支持多设备之间移动数据进行计算\n",
    "# 默认创建在 gpu 0 上\n",
    "X_cpu.device, X_gpu.device, X_gpu_0.device # 放在了 index=0 就是第 0 号 cpu 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cpu.cuda(0) # 从 cpu 上拷贝一份数据到 0 号 gpu 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果一个数据本身就在 gpu 上了，\n",
    "# 那么使用 cuda 方法拷贝到其他 gpu 中是不会执行的,\n",
    "# 还是返回当前数据所在的 gpu 的数据，\n",
    "# 返回自己：出于性能的考虑\n",
    "X_gpu.cuda(0) is X_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络与 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1155],\n",
       "        [1.1155]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(3, 1)\n",
    ")\n",
    "\n",
    "# 把神经网络移动到 gpu 中\n",
    "net = net.to(device=torch.device('cuda'))\n",
    "res = net(X_gpu)\n",
    "res # 可以发现 res 也存储在了 gpu 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确认模型参数存储在同一个 GPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问神经网络的第 0 层的权重\n",
    "# 权重的张量也存储在 gpu 上边\n",
    "net[0].weight.data.device"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ec60190fd82d19059a2c75283b4d0c60a6036d5032fb7c4db6e5c318b4fdfbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
